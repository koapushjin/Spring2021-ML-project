{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(true, pred):\n",
    "    error = np.square(np.subtract(true,pred)).mean(axis=0)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-94096a655efd>:9: RuntimeWarning: divide by zero encountered in log\n",
      "  y = np.log(df[['like','forward','comment']])\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(\"raw_data.xlsx\",skiprows=1,usecols=[\"微博正文\",\"点赞数\",\"转发数\",\"评论数\"])\n",
    "df = df.rename(columns = {'微博正文':'text', '点赞数':'like', '转发数':'forward','评论数':'comment'}, inplace=False)\n",
    "\n",
    "f = open('tfidf.txt', 'r')\n",
    "allsentences = f.readlines()\n",
    "\n",
    "for i in range(len(allsentences)):\n",
    "    allsentences[i] = allsentences[i].strip('\\n')\n",
    "y = np.log(df[['like','forward','comment']])\n",
    "f.close()\n",
    "#log几乎不影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = scipy.sparse.coo_matrix(y)\n",
    "for i, j, v in zip(t.row, t.col, t.data):\n",
    "    if (np.isnan(v) or np.isinf(v)):\n",
    "        y.iloc[i, j] = 0\n",
    "\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(allsentences[:50000], y[:50000], test_size=.3, train_size=.7, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "\n",
    "#该类会将文本中的词语转换为词频矩阵，矩阵元素a[i][j] 表示j词在i类文本下的词频\n",
    "vectorizer = CountVectorizer(max_features = 10000)\n",
    "#该类会统计每个词语的tf-idf权值\n",
    "tf_idf_transformer = TfidfTransformer()\n",
    "\n",
    "tf_idf1 = tf_idf_transformer.fit_transform(vectorizer.fit_transform(X_train))\n",
    "X_train_weight = tf_idf1\n",
    "#将tf-idf矩阵抽取出来，元素a[i][j]表示j词在i类文本中的tf-idf权重\n",
    "\n",
    "#对测试集进行tf-idf权重计算\n",
    "tf_idf2 = tf_idf_transformer.transform(vectorizer.transform(X_test))\n",
    "X_test_weight = tf_idf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr = sklearn.svm.SVR(kernel ='rbf',degree = 3, gamma ='auto', coef0 = 0.0, tol = 0.001, C = 1.0,\n",
    "epsilon = 0.1, shrinking = True, cache_size = 200, verbose = False, max_iter = -1)\n",
    "\n",
    "svr.fit(X_train_weight, y_train['like'])\n",
    "y_train_pred0 = svr.predict(X_train_weight)\n",
    "y_test_pred0 = svr.predict(X_test_weight)\n",
    "\n",
    "svr.fit(X_train_weight, y_train['forward'])\n",
    "y_train_pred1 = svr.predict(X_train_weight)\n",
    "y_test_pred1 = svr.predict(X_test_weight)\n",
    "\n",
    "svr.fit(X_train_weight, y_train['comment'])\n",
    "y_train_pred2 = svr.predict(X_train_weight)\n",
    "y_test_pred2 = svr.predict(X_test_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "like       5002.900623\n",
      "forward    4422.304667\n",
      "comment    1188.533845\n",
      "dtype: float64\n",
      "like       4909.050937\n",
      "forward    3373.718870\n",
      "comment    1213.058375\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = np.concatenate(([y_train_pred0], [y_train_pred1], [y_train_pred2]), axis=0)\n",
    "y_test_pred = np.concatenate(([y_test_pred0], [y_test_pred1], [y_test_pred2]), axis=0)\n",
    "\n",
    "train_error = np.absolute(np.subtract(np.exp(y_train),np.exp(y_train_pred.T))).mean(axis=0)\n",
    "print(train_error)\n",
    "\n",
    "test_error = np.absolute(np.subtract(np.exp(y_test),np.exp(y_test_pred.T))).mean(axis=0)\n",
    "print(test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr1 = sklearn.svm.SVR(kernel ='poly',degree = 3, gamma ='auto', coef0 = 0.0, tol = 0.001, C = 1.0,\n",
    "epsilon = 0.1, shrinking = True, cache_size = 200, verbose = False, max_iter = -1)\n",
    "\n",
    "svr1.fit(X_train_weight, y_train['like'])\n",
    "y_train_pred0 = svr.predict(X_train_weight)\n",
    "y_test_pred0 = svr.predict(X_test_weight)\n",
    "\n",
    "svr1.fit(X_train_weight, y_train['forward'])\n",
    "y_train_pred1 = svr.predict(X_train_weight)\n",
    "y_test_pred1 = svr.predict(X_test_weight)\n",
    "\n",
    "svr1.fit(X_train_weight, y_train['comment'])\n",
    "y_train_pred2 = svr.predict(X_train_weight)\n",
    "y_test_pred2 = svr.predict(X_test_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "like       5618.077962\n",
      "forward    4660.494981\n",
      "comment    1190.669840\n",
      "dtype: float64\n",
      "like       5512.656311\n",
      "forward    3612.471748\n",
      "comment    1215.079982\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = np.concatenate(([y_train_pred0], [y_train_pred1], [y_train_pred2]), axis=0)\n",
    "y_test_pred = np.concatenate(([y_test_pred0], [y_test_pred1], [y_test_pred2]), axis=0)\n",
    "    \n",
    "train_error = np.absolute(np.subtract(np.exp(y_train),np.exp(y_train_pred.T))).mean(axis=0)\n",
    "print(train_error)\n",
    "\n",
    "test_error = np.absolute(np.subtract(np.exp(y_test),np.exp(y_test_pred.T))).mean(axis=0)\n",
    "print(test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-0f9bd8ac3d52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msvr2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'like'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0my_train_pred0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0my_test_pred0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_dense_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_sparse_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m  \u001b[0;31m# C is not useful here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m         return libsvm_sparse.libsvm_sparse_predict(\n\u001b[0m\u001b[1;32m    370\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupport_vectors_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "svr2 = sklearn.svm.SVR(kernel ='sigmoid',degree = 3, gamma ='auto', coef0 = 0.0, tol = 0.001, C = 1.0,\n",
    "epsilon = 0.1, shrinking = True, cache_size = 200, verbose = False, max_iter = -1)\n",
    "\n",
    "svr2.fit(X_train_weight, y_train['like'])\n",
    "y_train_pred0 = svr.predict(X_train_weight)\n",
    "y_test_pred0 = svr.predict(X_test_weight)\n",
    "\n",
    "svr2.fit(X_train_weight, y_train['forward'])\n",
    "y_train_pred1 = svr.predict(X_train_weight)\n",
    "y_test_pred1 = svr.predict(X_test_weight)\n",
    "\n",
    "svr2.fit(X_train_weight, y_train['comment'])\n",
    "y_train_pred2 = svr.predict(X_train_weight)\n",
    "y_test_pred2 = svr.predict(X_test_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = np.concatenate(([y_train_pred0], [y_train_pred1], [y_train_pred2]), axis=0)\n",
    "y_test_pred = np.concatenate(([y_test_pred0], [y_test_pred1], [y_test_pred2]), axis=0)\n",
    "\n",
    "train_error = np.absolute(np.subtract(np.exp(y_train),np.exp(y_train_pred.T))).mean(axis=0)\n",
    "print(train_error)\n",
    "\n",
    "test_error = np.absolute(np.subtract(np.exp(y_test),np.exp(y_test_pred.T))).mean(axis=0)\n",
    "print(test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
